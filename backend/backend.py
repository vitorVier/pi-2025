from flask import Flask, request, jsonify
from flask_cors import CORS
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import os
import joblib # Usado para salvar e carregar o modelo
import sqlite3
from datetime import datetime
from db import obter_total_diagnosticos

# --- Configura√ß√£o da Aplica√ß√£o ---
app = Flask(__name__)
CORS(app)

# Conex√£o √∫nica com SQLite
conn = sqlite3.connect("diagnosticos.db", check_same_thread=False)
cursor = conn.cursor()

# Cria tabela se n√£o existir
cursor.execute("""
CREATE TABLE IF NOT EXISTS relatorios (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    total_diagnosticos INTEGER,
    data TEXT
)
""")
conn.commit()

def salvar_relatorio(total_diagnosticos: int):
    data = datetime.now().isoformat()
    cursor.execute(
        "INSERT INTO relatorios (total_diagnosticos, data) VALUES (?, ?)",
        (total_diagnosticos, data)
    )
    conn.commit()

def obter_ultimo_relatorio():
    row = cursor.execute(
        "SELECT * FROM relatorios ORDER BY id DESC LIMIT 1"
    ).fetchone()
    if row:
        return {"id": row[0], "total_diagnosticos": row[1], "data": row[2]}
    return {"id": 0, "total_diagnosticos": 0, "data": ""}

# --- Constantes e Vari√°veis Globais ---
MODEL_PATH = 'diabetes_model.joblib'
MODEL_COLUMNS_PATH = 'model_columns.joblib'
CLASS_MAPPING_PATH = 'class_mapping.joblib'
CSV_PATH = 'backend/dados_dediabetes_completos.csv'

# Vari√°veis para armazenar o modelo e as colunas em mem√≥ria
model = None
model_columns = None
class_mapping = None

# --- Fun√ß√µes Auxiliares ---

def load_model():
    """ Carrega o modelo, as colunas e o mapeamento de classes do disco. """
    global model, model_columns, class_mapping
    try:
        if all(os.path.exists(p) for p in [MODEL_PATH, MODEL_COLUMNS_PATH, CLASS_MAPPING_PATH]):
            print("üß† Carregando modelo, colunas e mapeamento existentes...")
            model = joblib.load(MODEL_PATH)
            model_columns = joblib.load(MODEL_COLUMNS_PATH)
            class_mapping = joblib.load(CLASS_MAPPING_PATH)
            print("‚úÖ Modelo carregado com sucesso!")
        else:
            print("‚ö†Ô∏è Arquivos de modelo n√£o encontrados. Treine o modelo primeiro via GET /train.")
    except Exception as e:
        print(f"‚ùå Erro ao carregar o modelo: {e}")

# --- Rotas da API ---

@app.route('/')
def home():
    """ Rota inicial para verificar se o servidor est√° no ar. """
    return "Servidor rodando! GET /train para treinar, POST /diagnosticar para prever."

@app.route('/train', methods=['GET'])
def train_model():
    """ Carrega, pr√©-processa, treina e salva o modelo de machine learning. """
    global model, model_columns, class_mapping
    try:
        print("üîÑ Iniciando o processo de treinamento...")
        if not os.path.exists(CSV_PATH):
            return jsonify({"error": f"Arquivo de dados n√£o encontrado: {CSV_PATH}"}), 404
        
        df = pd.read_csv(CSV_PATH)
        df.columns = df.columns.str.strip()
        print(f"üìä Dados carregados: {df.shape[0]} linhas, {df.shape[1]} colunas.")

        # --- Pr√©-processamento ---
        def converter_tempo_para_semanas(valor):
            if pd.isna(valor): return 0
            valor_str = str(valor).lower()
            numeros = ''.join(filter(str.isdigit, valor_str))
            if not numeros: return 0
            num = int(numeros)
            if 'semana' in valor_str: return num
            if 'm√™s' in valor_str or 'mes' in valor_str: return num * 4
            if 'ano' in valor_str: return num * 52
            return 0

        if 'tempo_sintomas' in df.columns:
            df['tempo_sintomas'] = df['tempo_sintomas'].apply(converter_tempo_para_semanas)
        
        # Mapeia colunas bin√°rias conhecidas
        mapeamento_binario = {'sim': 1, 'n√£o': 0, 'masculino': 0, 'feminino': 1}
        # Seleciona colunas que podem ser mapeadas
        cols_to_map = [col for col in df.columns if set(df[col].unique()).issubset(mapeamento_binario.keys())]
        df[cols_to_map] = df[cols_to_map].replace(mapeamento_binario)
        print(f"‚úÖ Colunas bin√°rias mapeadas: {cols_to_map}")

        if 'tipo_diabetes' not in df.columns:
            return jsonify({"error": "Coluna alvo 'tipo_diabetes' n√£o encontrada."}), 400

        # Separa o alvo (y) antes de processar as features (X)
        y_labels = df['tipo_diabetes'].astype('category')
        temp_class_mapping = {code: label for code, label in enumerate(y_labels.cat.categories)}
        y = y_labels.cat.codes
        X = df.drop(columns=['tipo_diabetes'])
        print(f"üîÑ Mapeamento de classes: {temp_class_mapping}")

        # *** CORRE√á√ÉO: Converte TODAS as colunas de texto restantes para num√©rico ***
        categorical_cols = X.select_dtypes(include=['object']).columns
        if len(categorical_cols) > 0:
            print(f"üîç Codificando colunas de texto: {list(categorical_cols)}")
            X = pd.get_dummies(X, columns=categorical_cols, prefix=categorical_cols)
            print("‚úÖ Colunas de texto convertidas com One-Hot Encoding.")
        
        # Agora, X √© totalmente num√©rico
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
        
        # --- Pipeline e Treinamento ---
        pipeline = Pipeline([
            ('scaler', StandardScaler()),
            ('clf', RandomForestClassifier(random_state=42, class_weight='balanced'))
        ])
        param_grid = {
            'clf__n_estimators': [100, 200],
            'clf__max_depth': [10, 20],
            'clf__min_samples_leaf': [1, 2]
        }
        
        grid_search = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, verbose=1, scoring='accuracy')
        grid_search.fit(X_train, y_train)

        best_model = grid_search.best_estimator_
        accuracy = best_model.score(X_test, y_test)
        
        # Salva o modelo, a ordem das colunas e o mapeamento de classes
        joblib.dump(best_model, MODEL_PATH)
        joblib.dump(list(X.columns), MODEL_COLUMNS_PATH) # Salva colunas ap√≥s get_dummies
        joblib.dump(temp_class_mapping, CLASS_MAPPING_PATH)

        # Atualiza as vari√°veis globais
        model, model_columns, class_mapping = best_model, list(X.columns), temp_class_mapping

        print(f"üéØ Acur√°cia final: {accuracy:.4f}")
        print(f"üíæ Modelo, colunas e mapeamento salvos com sucesso!")

        return jsonify({
            "mensagem": "Modelo treinado e salvo com sucesso!",
            "acuracia": round(accuracy, 4),
            "melhores_parametros": grid_search.best_params_
        })

    except Exception as e:
        print(f"‚ùå Erro inesperado durante o treinamento: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": "Ocorreu um erro interno durante o treinamento.", "detalhes": str(e)}), 500

@app.route('/diagnosticar', methods=['POST'])
def diagnosticar():
    """ Recebe dados de um paciente e retorna um diagn√≥stico. """
    if model is None:
        return jsonify({"error": "Modelo n√£o treinado. Acesse GET /train primeiro."}), 400

    try:
        dados_paciente = request.json
        print(f"üì• Recebidos dados para diagn√≥stico: {dados_paciente}")

        df_paciente = pd.DataFrame([dados_paciente])

        # Pr√©-processamento id√™ntico ao de treino para os dados do paciente
        df_paciente.replace('', 0, inplace=True)  # evita convers√£o errada de string vazia

        # Colunas bin√°rias
        df_paciente.replace({'sim': 1, 'n√£o': 0, 'masculino': 0, 'feminino': 1}, inplace=True)
        
        # Garante que o DataFrame do paciente tenha as mesmas colunas do modelo
        # Adiciona colunas faltantes (dummies) com valor 0 e remove extras
        df_final = pd.DataFrame(columns=model_columns)
        df_final = pd.concat([df_final, df_paciente], ignore_index=True, sort=False).fillna(0)
        df_final = df_final[model_columns] # Garante a ordem e remove colunas extras

        # Faz a predi√ß√£o
        predicao_codigo = model.predict(df_final)[0]
        probabilidades = model.predict_proba(df_final)[0]
        
        diagnostico = class_mapping.get(predicao_codigo, "Desconhecido")
        confianca = round(probabilidades.max() * 100, 2)
        
        print(f"üîç Diagn√≥stico: {diagnostico} com {confianca}% de confian√ßa.")
        
        return jsonify({
            "diagnostico": diagnostico,
            "confianca_percentual": confianca
        })

    except Exception as e:
        print(f"‚ùå Erro na predi√ß√£o: {e}")
        return jsonify({"error": "Erro ao processar o diagn√≥stico.", "detalhes": str(e)}), 500

@app.route('/relatorio', methods=['GET'])
def relatorio():
    total = obter_total_diagnosticos()
    return jsonify({'total_diagnosticos': total})

# --- Execu√ß√£o da Aplica√ß√£o ---
if __name__ == '__main__':
    load_model() # Tenta carregar um modelo existente ao iniciar
    app.run(host='0.0.0.0', port=5000, debug=True)
